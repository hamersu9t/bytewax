<main class="api__content">
<article class="api__article" id="content">
<header class="api__article-header">
<h1 class="api__article-title">Module <strong>bytewax.execution</strong></h1>
</header>
<section class="api__article-intro" id="section-intro">
<p>How to execute your dataflows.</p>
<p>Run an instantiated <code><a title="bytewax.dataflow.Dataflow" href="dataflow.html#bytewax.dataflow.Dataflow">Dataflow</a></code> using one of the entry
point functions in this module.</p>
<h2 id="epoch-configs">Epoch Configs</h2>
<p>Epochs define the granularity of recovery in a bytewax dataflow. By default, we
snapshot recovery every 10 seconds. You should only need to set this if you are
testing the recovery system or are doing deep exactly-once integration work. Changing
this does not change the semantics of any of the operators.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre class="language-python line-numbers"><code class="language-python">&#34;&#34;&#34;How to execute your dataflows.

Run an instantiated `bytewax.dataflow.Dataflow` using one of the entry
point functions in this module.


Epoch Configs
-------------

Epochs define the granularity of recovery in a bytewax dataflow. By default, we
snapshot recovery every 10 seconds. You should only need to set this if you are 
testing the recovery system or are doing deep exactly-once integration work. Changing
this does not change the semantics of any of the operators.


&#34;&#34;&#34;
from typing import Any, Iterable, List, Optional, Tuple

from multiprocess import get_context

from bytewax.dataflow import Dataflow
from bytewax.recovery import RecoveryConfig

from .bytewax import (  # noqa: F401
    run_main,
    cluster_main,
    EpochConfig,
    PeriodicEpochConfig,
    TestingEpochConfig,
)

# Due to our package structure, we need to define __all__
# in any submodule as pdoc will not find the documentation
# for functions imported here, but defined in another submodule.
# See https://pdoc3.github.io/pdoc/doc/pdoc/#what-objects-are-documented
# for more information.
__all__ = [
    &#34;run_main&#34;,
    &#34;cluster_main&#34;,
    &#34;spawn_cluster&#34;,
    &#34;EpochConfig&#34;,
    &#34;PeriodicEpochConfig&#34;,
    &#34;TestingEpochConfig&#34;,
]


def _gen_addresses(proc_count: int) -&gt; Iterable[str]:
    return [f&#34;localhost:{proc_id + 2101}&#34; for proc_id in range(proc_count)]


def spawn_cluster(
    flow: Dataflow,
    *,
    epoch_config: Optional[EpochConfig] = None,
    recovery_config: Optional[RecoveryConfig] = None,
    proc_count: int = 1,
    worker_count_per_proc: int = 1,
    mp_ctx=get_context(&#34;spawn&#34;),
) -&gt; List[Tuple[int, Any]]:
    &#34;&#34;&#34;Execute a dataflow as a cluster of processes on this machine.

    Blocks until execution is complete.

    Starts up cluster processes for you and handles connecting them
    together. You&#39;d commonly use this for notebook analysis that needs
    parallelism and higher throughput, or simple stand-alone demo
    programs.

    &gt;&gt;&gt; from bytewax.testing import doctest_ctx
    &gt;&gt;&gt; from bytewax.dataflow import Dataflow
    &gt;&gt;&gt; from bytewax.inputs import TestingInputConfig
    &gt;&gt;&gt; from bytewax.outputs import StdOutputConfig
    &gt;&gt;&gt; flow = Dataflow()
    &gt;&gt;&gt; flow.input(&#34;inp&#34;, TestingInputConfig(range(3)))
    &gt;&gt;&gt; flow.capture(StdOutputConfig())
    &gt;&gt;&gt; spawn_cluster(
    ...     flow,
    ...     proc_count=2,
    ...     mp_ctx=doctest_ctx,  # Outside a doctest, you&#39;d skip this.
    ... )  # doctest: +ELLIPSIS
    (...)

    See `bytewax.run_main()` for a way to test input and output
    builders without the complexity of starting a cluster.

    See `bytewax.cluster_main()` for starting one process in a cluster
    in a distributed situation.

    Args:

        flow: Dataflow to run.

        epoch_config: A custom epoch config. You probably don&#39;t need
            this. See `EpochConfig` for more info.

        recovery_config: State recovery config. See
            `bytewax.recovery`. If `None`, state will not be
            persisted.

        proc_count: Number of processes to start.

        worker_count_per_proc: Number of worker threads to start on
            each process.

        mp_ctx: `multiprocessing` context to use. Use this to
            configure starting up subprocesses via spawn or
            fork. Defaults to spawn.

    &#34;&#34;&#34;
    addresses = _gen_addresses(proc_count)
    with mp_ctx.Pool(processes=proc_count) as pool:
        futures = [
            pool.apply_async(
                cluster_main,
                (flow,),
                {
                    &#34;epoch_config&#34;: epoch_config,
                    &#34;recovery_config&#34;: recovery_config,
                    &#34;addresses&#34;: addresses,
                    &#34;proc_id&#34;: proc_id,
                    &#34;worker_count_per_proc&#34;: worker_count_per_proc,
                },
            )
            for proc_id in range(proc_count)
        ]
        pool.close()

        for future in futures:
            # Will re-raise exceptions from subprocesses.
            future.get()

        pool.join()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="api__article-subtitle" id="header-functions">Functions</h2>
<dl>
<dt id="bytewax.execution.cluster_main"><code class="language-python name flex">
<span>def <span class="ident">cluster_main</span></span>(<span>flow, addresses, proc_id, *, epoch_config, recovery_config, worker_count_per_proc)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute a dataflow in the current process as part of a cluster.</p>
<p>You have to coordinate starting up all the processes in the
cluster and ensuring they each are assigned a unique ID and know
the addresses of other processes. You'd commonly use this for
starting processes as part of a Kubernetes cluster.</p>
<p>Blocks until execution is complete.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; from bytewax.dataflow import Dataflow
&gt;&gt;&gt; from bytewax.inputs import TestingInputConfig
&gt;&gt;&gt; from bytewax.outputs import StdOutputConfig
&gt;&gt;&gt; flow = Dataflow()
&gt;&gt;&gt; flow.input(&quot;inp&quot;, TestingInputConfig(range(3)))
&gt;&gt;&gt; flow.capture(StdOutputConfig())
&gt;&gt;&gt; addresses = []  # In a real example, you'd find the &quot;host:port&quot; of all other Bytewax workers.
&gt;&gt;&gt; proc_id = 0  # In a real example, you'd assign each worker a distinct ID from 0..proc_count.
&gt;&gt;&gt; cluster_main(flow, addresses, proc_id)
0
1
2
</code></pre>
<p>See <code>bytewax.run_main()</code> for a way to test input and output
builders without the complexity of starting a cluster.</p>
<p>See <code>bytewax.spawn_cluster()</code> for starting a simple cluster
locally on one machine.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>flow</code></strong></dt>
<dd>Dataflow to run.</dd>
<dt><strong><code>addresses</code></strong></dt>
<dd>List of host/port addresses for all processes in
this cluster (including this one).</dd>
<dt><strong><code>proc_id</code></strong></dt>
<dd>Index of this process in cluster; starts from 0.</dd>
<dt><strong><code>epoch_config</code></strong></dt>
<dd>A custom epoch config. You probably don't need
this. See <code><a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a></code> for more info.</dd>
<dt><strong><code>recovery_config</code></strong></dt>
<dd>State recovery config. See
<code><a title="bytewax.recovery" href="recovery.html">bytewax.recovery</a></code>. If <code>None</code>, state will not be
persisted.</dd>
<dt><strong><code>worker_count_per_proc</code></strong></dt>
<dd>Number of worker threads to start on
each process.</dd>
</dl></div>
</dd>
<dt id="bytewax.execution.run_main"><code class="language-python name flex">
<span>def <span class="ident">run_main</span></span>(<span>flow, *, epoch_config, recovery_config)</span>
</code></dt>
<dd>
<div class="desc"><p>Execute a dataflow in the current thread.</p>
<p>Blocks until execution is complete.</p>
<p>You'd commonly use this for prototyping custom input and output
builders with a single worker before using them in a cluster
setting.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; from bytewax.dataflow import Dataflow
&gt;&gt;&gt; from bytewax.inputs import TestingInputConfig
&gt;&gt;&gt; from bytewax.outputs import StdOutputConfig
&gt;&gt;&gt; flow = Dataflow()
&gt;&gt;&gt; flow.input(&quot;inp&quot;, TestingInputConfig(range(3)))
&gt;&gt;&gt; flow.capture(StdOutputConfig())
&gt;&gt;&gt; run_main(flow)
0
1
2
</code></pre>
<p>See <code>bytewax.spawn_cluster()</code> for starting a cluster on this
machine with full control over inputs and outputs.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>flow</code></strong></dt>
<dd>Dataflow to run.</dd>
<dt><strong><code>epoch_config</code></strong></dt>
<dd>A custom epoch config. You probably don't need
this. See <code><a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a></code> for more info.</dd>
<dt><strong><code>recovery_config</code></strong></dt>
<dd>State recovery config. See
<code><a title="bytewax.recovery" href="recovery.html">bytewax.recovery</a></code>. If <code>None</code>, state will not be
persisted.</dd>
</dl></div>
</dd>
<dt id="bytewax.execution.spawn_cluster"><code class="language-python name flex">
<span>def <span class="ident">spawn_cluster</span></span>(<span>flow: <a title="bytewax.dataflow.Dataflow" href="dataflow.html#bytewax.dataflow.Dataflow">Dataflow</a>, *, epoch_config: Optional[<a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a>] = None, recovery_config: Optional[<a title="bytewax.recovery.RecoveryConfig" href="recovery.html#bytewax.recovery.RecoveryConfig">RecoveryConfig</a>] = None, proc_count: int = 1, worker_count_per_proc: int = 1, mp_ctx=&lt;multiprocess.context.SpawnContext object&gt;) ‑> List[Tuple[int, Any]]</span>
</code></dt>
<dd>
<div class="desc"><p>Execute a dataflow as a cluster of processes on this machine.</p>
<p>Blocks until execution is complete.</p>
<p>Starts up cluster processes for you and handles connecting them
together. You'd commonly use this for notebook analysis that needs
parallelism and higher throughput, or simple stand-alone demo
programs.</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; from bytewax.testing import doctest_ctx
&gt;&gt;&gt; from bytewax.dataflow import Dataflow
&gt;&gt;&gt; from bytewax.inputs import TestingInputConfig
&gt;&gt;&gt; from bytewax.outputs import StdOutputConfig
&gt;&gt;&gt; flow = Dataflow()
&gt;&gt;&gt; flow.input(&quot;inp&quot;, TestingInputConfig(range(3)))
&gt;&gt;&gt; flow.capture(StdOutputConfig())
&gt;&gt;&gt; spawn_cluster(
...     flow,
...     proc_count=2,
...     mp_ctx=doctest_ctx,  # Outside a doctest, you'd skip this.
... )  # doctest: +ELLIPSIS
(...)
</code></pre>
<p>See <code>bytewax.run_main()</code> for a way to test input and output
builders without the complexity of starting a cluster.</p>
<p>See <code>bytewax.cluster_main()</code> for starting one process in a cluster
in a distributed situation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>flow</code></strong></dt>
<dd>Dataflow to run.</dd>
<dt><strong><code>epoch_config</code></strong></dt>
<dd>A custom epoch config. You probably don't need
this. See <code><a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a></code> for more info.</dd>
<dt><strong><code>recovery_config</code></strong></dt>
<dd>State recovery config. See
<code><a title="bytewax.recovery" href="recovery.html">bytewax.recovery</a></code>. If <code>None</code>, state will not be
persisted.</dd>
<dt><strong><code>proc_count</code></strong></dt>
<dd>Number of processes to start.</dd>
<dt><strong><code>worker_count_per_proc</code></strong></dt>
<dd>Number of worker threads to start on
each process.</dd>
<dt><strong><code>mp_ctx</code></strong></dt>
<dd><code>multiprocessing</code> context to use. Use this to
configure starting up subprocesses via spawn or
fork. Defaults to spawn.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre class="language-python line-numbers"><code class="language-python">def spawn_cluster(
    flow: Dataflow,
    *,
    epoch_config: Optional[EpochConfig] = None,
    recovery_config: Optional[RecoveryConfig] = None,
    proc_count: int = 1,
    worker_count_per_proc: int = 1,
    mp_ctx=get_context(&#34;spawn&#34;),
) -&gt; List[Tuple[int, Any]]:
    &#34;&#34;&#34;Execute a dataflow as a cluster of processes on this machine.

    Blocks until execution is complete.

    Starts up cluster processes for you and handles connecting them
    together. You&#39;d commonly use this for notebook analysis that needs
    parallelism and higher throughput, or simple stand-alone demo
    programs.

    &gt;&gt;&gt; from bytewax.testing import doctest_ctx
    &gt;&gt;&gt; from bytewax.dataflow import Dataflow
    &gt;&gt;&gt; from bytewax.inputs import TestingInputConfig
    &gt;&gt;&gt; from bytewax.outputs import StdOutputConfig
    &gt;&gt;&gt; flow = Dataflow()
    &gt;&gt;&gt; flow.input(&#34;inp&#34;, TestingInputConfig(range(3)))
    &gt;&gt;&gt; flow.capture(StdOutputConfig())
    &gt;&gt;&gt; spawn_cluster(
    ...     flow,
    ...     proc_count=2,
    ...     mp_ctx=doctest_ctx,  # Outside a doctest, you&#39;d skip this.
    ... )  # doctest: +ELLIPSIS
    (...)

    See `bytewax.run_main()` for a way to test input and output
    builders without the complexity of starting a cluster.

    See `bytewax.cluster_main()` for starting one process in a cluster
    in a distributed situation.

    Args:

        flow: Dataflow to run.

        epoch_config: A custom epoch config. You probably don&#39;t need
            this. See `EpochConfig` for more info.

        recovery_config: State recovery config. See
            `bytewax.recovery`. If `None`, state will not be
            persisted.

        proc_count: Number of processes to start.

        worker_count_per_proc: Number of worker threads to start on
            each process.

        mp_ctx: `multiprocessing` context to use. Use this to
            configure starting up subprocesses via spawn or
            fork. Defaults to spawn.

    &#34;&#34;&#34;
    addresses = _gen_addresses(proc_count)
    with mp_ctx.Pool(processes=proc_count) as pool:
        futures = [
            pool.apply_async(
                cluster_main,
                (flow,),
                {
                    &#34;epoch_config&#34;: epoch_config,
                    &#34;recovery_config&#34;: recovery_config,
                    &#34;addresses&#34;: addresses,
                    &#34;proc_id&#34;: proc_id,
                    &#34;worker_count_per_proc&#34;: worker_count_per_proc,
                },
            )
            for proc_id in range(proc_count)
        ]
        pool.close()

        for future in futures:
            # Will re-raise exceptions from subprocesses.
            future.get()

        pool.join()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="api__article-subtitle" id="header-classes">Classes</h2>
<dl>
<dt id="bytewax.execution.EpochConfig"><code class="language-python flex name class">
<span>class <span class="ident">EpochConfig</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base class for an epoch config.</p>
<p>These define how epochs are assigned on source input data. You
should only need to set this if you are testing the recovery
system or are doing deep exactly-once integration work. Changing
this does not change the semantics of any of the operators.</p>
<p>Use a specific subclass of this for the epoch definition you need.</p></div>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="bytewax.execution.TestingEpochConfig" href="#bytewax.execution.TestingEpochConfig">TestingEpochConfig</a></li>
<li>bytewax.window.PeriodicEpochConfig</li>
</ul>
</dd>
<dt id="bytewax.execution.PeriodicEpochConfig"><code class="language-python flex name class">
<span>class <span class="ident">PeriodicEpochConfig</span></span>
<span>(</span><span>epoch_length)</span>
</code></dt>
<dd>
<div class="desc"><p>Increment epochs at regular system time intervals.</p>
<p>This is the default with 10 second epoch intervals if no
<code>epoch_config</code> is passed to your execution entry point.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>epoch_length</code></strong> :&ensp;<code>datetime.timedelta</code></dt>
<dd>System time length of each
epoch.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Config object. Pass this as the <code>epoch_config</code> parameter of
your execution entry point.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="bytewax.execution.PeriodicEpochConfig.epoch_length"><code class="language-python name">var <span class="ident">epoch_length</span></code></dt>
<dd>
<div class="desc"><p>Return an attribute of instance, which is of type owner.</p></div>
</dd>
</dl>
</dd>
<dt id="bytewax.execution.TestingEpochConfig"><code class="language-python flex name class">
<span>class <span class="ident">TestingEpochConfig</span></span>
</code></dt>
<dd>
<div class="desc"><p>Use for deterministic epochs in tests. Increment epoch by 1 after
each item.</p>
<p><em>This requires all workers to have exactly the same number of
input items! Otherwise the dataflow will hang!</em></p>
<p>You almost assuredly do not want to use this unless you are
writing tests of the recovery system.</p>
<h2 id="returns">Returns</h2>
<p>Config object. Pass this as the <code>epoch_config</code> parameter of
your execution entry point.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a></li>
</ul>
</dd>
</dl>
</section>
<footer class="api__footer" id="footer">
<p class="api__footer-copyright">
Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.
</p>
</footer>
</article>
<nav class="api__sidebar" id="sidebar">
<ul class="api__sidebar-nav" id="index">
<li class="api__sidebar-nav-item">
<h3 class="api__sidebar-nav-title">Super-module</h3>
<ul class="api__sidebar-nav-menu">
<li class="api__sidebar-nav-menu-item">
<a class="api__sidebar-nav-menu-link api-supermodule" href="/apidocs">
bytewax
</a>
</li>
</ul>
</li>
<li class="api__sidebar-nav-item">
<h3 class="api__sidebar-nav-title"><a href="#header-functions">Functions</a></h3>
<ul class="api__sidebar-nav-menu">
<li class="api__sidebar-nav-menu-item"><a title="bytewax.execution.cluster_main" href="#bytewax.execution.cluster_main">cluster_main</a></li>
<li class="api__sidebar-nav-menu-item"><a title="bytewax.execution.run_main" href="#bytewax.execution.run_main">run_main</a></li>
<li class="api__sidebar-nav-menu-item"><a title="bytewax.execution.spawn_cluster" href="#bytewax.execution.spawn_cluster">spawn_cluster</a></li>
</ul>
</li>
<li class="api__sidebar-nav-item">
<h3 class="api__sidebar-nav-title"><a href="#header-classes">Classes</a></h3>
<ul class="api__sidebar-nav-classes">
<li class="api__sidebar-nav-classes-item">
<h4 class="api__sidebar-nav-classes-title"><a title="bytewax.execution.EpochConfig" href="#bytewax.execution.EpochConfig">EpochConfig</a></h4>
</li>
<li class="api__sidebar-nav-classes-item">
<h4 class="api__sidebar-nav-classes-title"><a title="bytewax.execution.PeriodicEpochConfig" href="#bytewax.execution.PeriodicEpochConfig">PeriodicEpochConfig</a></h4>
<ul class="api__sidebar-nav-menu">
<li class="api__sidebar-nav-menu-item"><a title="bytewax.execution.PeriodicEpochConfig.epoch_length" href="#bytewax.execution.PeriodicEpochConfig.epoch_length">epoch_length</a></li>
</ul>
</li>
<li class="api__sidebar-nav-classes-item">
<h4 class="api__sidebar-nav-classes-title"><a title="bytewax.execution.TestingEpochConfig" href="#bytewax.execution.TestingEpochConfig">TestingEpochConfig</a></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>